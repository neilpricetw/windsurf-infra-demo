name: Terraform CI

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      destroy:
        description: 'Destroy resources instead of apply?'
        required: false
        default: false
        type: boolean

permissions:
  id-token: write
  contents: read

jobs:
  terraform:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./terraform-eks
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install tfenv
        run: |
          git clone --depth=1 https://github.com/tfutils/tfenv.git ~/.tfenv
          echo "$HOME/.tfenv/bin" >> $GITHUB_PATH

      - name: Install and use Terraform with tfenv
        run: |
          tfenv install
          tfenv use

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::160071257600:role/github-actions-terraform
          aws-region: ap-southeast-2

      - name: Terraform Format
        run: terraform fmt -check -recursive

      - name: Terraform Init
        run: terraform init -reconfigure

      - name: Terraform Validate
        run: terraform validate

      - name: Terraform Test
        run: terraform test

      - name: Terraform Plan
        run: terraform plan

      - name: Terraform Apply or Destroy
        run: |
          if [[ "${{ github.event.inputs.destroy }}" == "true" ]]; then
            echo "Running terraform destroy..."
            terraform destroy -auto-approve
          else
            echo "Running terraform apply..."
            terraform apply -auto-approve
          fi

      - name: Export Kubernetes Provider Vars
        id: export-kube-vars
        run: |
          CLUSTER_NAME="np-eks-fargate"
          AWS_REGION="ap-southeast-2"
          export KUBE_HOST=$(aws eks describe-cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" --query 'cluster.endpoint' --output text)
          export KUBE_CA=$(aws eks describe-cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" --query 'cluster.certificateAuthority.data' --output text)
          export KUBE_TOKEN=$(aws eks get-token --cluster-name "$CLUSTER_NAME" --region "$AWS_REGION" --query 'status.token' --output text)
          echo "KUBE_HOST=$KUBE_HOST" >> $GITHUB_ENV
          echo "KUBE_CA=$KUBE_CA" >> $GITHUB_ENV
          echo "KUBE_TOKEN=$KUBE_TOKEN" >> $GITHUB_ENV

      - name: Kubectl Cluster Info
        run: |
          kubectl config set-cluster eks-ci --server="$KUBE_HOST" --certificate-authority=<(echo "$KUBE_CA" | base64 -d) --embed-certs=true
          kubectl config set-credentials gha-ci --token="$KUBE_TOKEN"
          kubectl config set-context gha-ci --cluster=eks-ci --user=gha-ci
          kubectl config use-context gha-ci
          kubectl cluster-info
